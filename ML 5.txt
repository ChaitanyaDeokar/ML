import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix



data = pd.read_csv("C:/Users/Chaitanya Deokar/Desktop/car_evaluation.csv")



data = data.apply(LabelEncoder().fit_transform)



X = data.iloc[:, :-1]  # Features (all columns except the last one)
y = data.iloc[:, -1]   # Target variable (last column)



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)



rf_classifier.fit(X_train, y_train)



y_pred = rf_classifier.predict(X_test)



accuracy = accuracy_score(y_test, y_pred)
confusion = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)


print(f"Accuracy: {accuracy}")
print("Confusion Matrix:\n", confusion)
print("Classification Report:\n", classification_rep)






















Certainly! This code is an example of using the scikit-learn library in Python to train a Random Forest Classifier on a dataset and evaluate its performance. I'll explain each part of the code in detail:

Importing Libraries:

It starts by importing the necessary Python libraries for working with data and machine learning:
pandas for data manipulation and analysis.
sklearn.model_selection for splitting the dataset into training and testing sets.
sklearn.preprocessing for encoding categorical (string) data.
sklearn.ensemble for the Random Forest Classifier.
sklearn.metrics for evaluating the model's performance.
Loading the Dataset:

The code loads a dataset from a CSV file named "car_evaluation.csv" using the pd.read_csv function and stores it in a DataFrame called data.
Encoding Categorical Data:

The dataset likely contains categorical (string) data. To work with machine learning algorithms, this code uses a LabelEncoder to convert the categorical data into numerical values. This helps the algorithm understand the data better.
Defining Features and Target Variable:

The code separates the dataset into two parts:
X: This contains the feature columns (all columns except the last one).
y: This contains the target variable (the last column).
Splitting the Dataset:

The dataset is split into training and testing sets using the train_test_split function. In this code, 80% of the data is used for training, and 20% is used for testing. The random_state parameter ensures reproducibility.
Creating a Random Forest Classifier:

The code creates a Random Forest Classifier with 100 decision trees (n_estimators=100) and sets a random seed for reproducibility (random_state=42).
Training the Classifier:

The Random Forest Classifier is trained on the training data using the fit method.
Making Predictions:

The trained classifier is used to make predictions on the test data, and the results are stored in y_pred.
Evaluating the Model:

Three evaluation metrics are calculated:
accuracy: It measures the proportion of correctly classified instances in the test data.
confusion: This is the confusion matrix, which shows the count of true positives, true negatives, false positives, and false negatives.
classification_rep: This is the classification report, providing metrics like precision, recall, and F1-score for each class in the dataset.
Printing the Results:

The code prints the accuracy, confusion matrix, and classification report to the console for further analysis and interpretation.
This code demonstrates a complete workflow for training a Random Forest Classifier on a dataset and assessing its performance using common machine learning evaluation metrics.
